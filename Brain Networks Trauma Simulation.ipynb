{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pulp\n",
    "import csv\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from pulp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Get adj_matrix from txt files.\n",
    "\n",
    "Inputs:\n",
    "filename - filename of a comma separated value file\n",
    "\n",
    "Output:\n",
    "adj_matrix - n*n matrix for n vertices where adj_matrix[i][j] represents a directed edge from i to j if its 1\n",
    "'''\n",
    "def read_txt(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        adj_matrix = list(reader)\n",
    "    adj_matrix = [[int(j) for j in i[0:(len(i))]] for i in adj_matrix]\n",
    "#     sinks = [any(row) for row in adj_matrix]\n",
    "#     sinks = [i for i, v in enumerate(sinks) if not v]\n",
    "#     adj_matrix_t = list(map(list, zip(*adj_matrix)))\n",
    "#     sources = [any(row) for row in adj_matrix_t]\n",
    "#     sources = [i for i, v in enumerate(sources) if not v]\n",
    "    return adj_matrix\n",
    "\n",
    "def write_txt(filename, Matrix):\n",
    "#     Matrix = read_txt('test.csv')\n",
    "    with open(filename, 'w', newline='') as csvfile:\n",
    "        spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "                                quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        [spamwriter.writerow(row) for row in Matrix]\n",
    "\n",
    "def nrow(Matrix):\n",
    "    return(len(Matrix))\n",
    "\n",
    "def ncol(Matrix):\n",
    "    return(len(Matrix[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Helper utility to preprocess our input graph\n",
    "\n",
    "Inputs:\n",
    "adj_matrix - n*n matrix for n vertices where adj_matrix[i][j] represents a directed edge from i to j if its 1\n",
    "sources - list of vertices that are sources eg: [0,2] where 0,2 would be valid rows and columns in adj_matrix\n",
    "sinks - list of vertices that are sinks eg: [3]\n",
    "\n",
    "Ouputs:\n",
    "adj_matrix - A new adj_matrix where a super source and super sink are added to handle multiple source/sink case\n",
    "edge_cap_facs - A list of variables representing edge capacity scaling factors (Our decision variable x)\n",
    "                Values would be of the form x_i_j which denotes capacity scaling factor for edge going from vertex i to j\n",
    "edge_flow_vals - A list of variables representing edge flow values (Variable y in LP)\n",
    "                 Values would be of the form y_i_j which denotes flow for edge going from vertex i to j\n",
    "vertex_dict - A list of dictionaries of form [{i:[],o:[]},{i:[],o:[]},..] \n",
    "              where i and o are input and output edges for that vertex (represented by index in this list)\n",
    "              the edges here would just be the corresponding edge flow variables defined in the edge_flow_vals list\n",
    "              so that this can be directly used to create flow conservation constraints in the LP\n",
    "'''\n",
    "def preprocess_graph(adj_matrix, sources, sinks):\n",
    "    n = len(adj_matrix) #Infer the size of adj_matrix\n",
    "    m = n+2 #New size of adjacency matrix as we add 2 new nodes, 1 super source and 1 super sink\n",
    "    \n",
    "    #Initialize the new_adj_matrix with zeros\n",
    "    new_adj_matrix = []\n",
    "    for i in range(m):\n",
    "        new_adj_matrix.append([])\n",
    "        for j in range(m):\n",
    "            new_adj_matrix[i].append(0)\n",
    "    #Copy over values from the original adj_matrix, \n",
    "    #basically the ith vertex in original matrix would become the (i+1)th vertex in the new matrix\n",
    "    for i in range(n):\n",
    "        new_adj_matrix[i+1][1:m-1] = adj_matrix[i]\n",
    "    \n",
    "    #Connect sources and sinks to new super source and super sink\n",
    "    #0 would always be the super source and m would always be the super sink\n",
    "    for s in sources:\n",
    "        new_adj_matrix[0][s+1] = 1\n",
    "\n",
    "    for t in sinks:\n",
    "        new_adj_matrix[t+1][m-1] = 1\n",
    "        \n",
    "    #The new adjacency matrix is created. \n",
    "    #Now we need to create the edge capacity factors, edge flow factors and vertex dict\n",
    "    edge_capacity_factors = []\n",
    "    edge_flows = []\n",
    "    vertex_dict = []\n",
    "    #Initialize vertex dict\n",
    "    for i in range(len(new_adj_matrix)):\n",
    "        vertex_dict.append({'i':[],'o':[]})\n",
    "        \n",
    "    for i in range(len(new_adj_matrix)):\n",
    "        for j in range(len(new_adj_matrix[i])):\n",
    "            if(new_adj_matrix[i][j] == 1):\n",
    "                ecf = 'x_'+str(i)+'_'+str(j)\n",
    "                ef = 'y_'+str(i)+'_'+str(j)\n",
    "                edge_capacity_factors.append(ecf)\n",
    "                edge_flows.append(ef)\n",
    "                #Outgoing for i\n",
    "                vertex_dict[i]['o'].append(ef)\n",
    "                #Incoming for j\n",
    "                vertex_dict[j]['i'].append(ef)\n",
    "                \n",
    "    return new_adj_matrix, edge_capacity_factors, edge_flows, vertex_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Cost function\n",
    "\n",
    "Inputs:\n",
    "x       - capacity of edge\n",
    "edge    - edge indice\n",
    "\n",
    "Outputs:\n",
    "y       - cost of assigning capacity of an edge to x\n",
    "'''\n",
    "def cost_function(x, edge):\n",
    "    return x-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_linear(pathIn, pathOut):\n",
    "    with open(pathIn + 'allComb.csv', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        allComb = list(reader)\n",
    "    for iRow in list(range(0, nrow(allComb))):\n",
    "#     for iRow in list(range(0, 3)):\n",
    "        print(\"processing: \"+str(iRow))\n",
    "        print(str(allComb[iRow]))\n",
    "        adj_matA = read_txt(filename=pathIn + 'adjm_A_' + str(iRow+1) + '.csv')\n",
    "        adj_matB = read_txt(filename=pathIn + 'adjm_B_' + str(iRow+1) + '.csv')\n",
    "        nSize   = int(allComb[iRow][0])\n",
    "        nSource = int(allComb[iRow][1])\n",
    "        nSink   = int(allComb[iRow][2])\n",
    "        pAddEdge= float(allComb[iRow][3])\n",
    "        nTrauma = int(allComb[iRow][4])\n",
    "        maxflowBefore = int(allComb[iRow][5])\n",
    "        maxflowAfter  = int(allComb[iRow][6])\n",
    "        #TODO: trauma size\n",
    "        #TODO: flow value?\n",
    "        #TODO: what if nSource != nSink\n",
    "        timeStart = time.time()\n",
    "        costBefore   = process_graph_LPSolver(adj_matrix=adj_matA, \n",
    "                                              cost_function=cost_function, \n",
    "                                              flow_val=maxflowBefore, \n",
    "                                              sources= list(range(0, nSource)),\n",
    "                                              sinks = list(range(nSize-nSink, nSize)))\n",
    "        timeCost  = time.time() - timeStart\n",
    "        costAfter   = process_graph_LPSolver(adj_matrix=adj_matB, \n",
    "                                              cost_function=cost_function, \n",
    "                                              flow_val=maxflowBefore, \n",
    "                                              sources= list(range(0, nSource)),\n",
    "                                              sinks = list(range(nSize-nSink, nSize)))\n",
    "        allComb[iRow].append(costBefore)\n",
    "        allComb[iRow].append(costAfter)\n",
    "        allComb[iRow].append(timeCost)\n",
    "        print(str(allComb[iRow]))\n",
    "    write_txt(pathOut + 'allComb_out.csv', allComb)\n",
    "    \n",
    "def test_linear_bnds(pathIn, pathOut):\n",
    "    with open(pathIn + 'allComb.csv', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        allComb = list(reader)\n",
    "    for iRow in list(range(0, nrow(allComb))):\n",
    "        print(\"processing: \"+str(iRow))\n",
    "        print(str(allComb[iRow]))\n",
    "        adj_matA = read_txt(filename=pathIn + str(iRow+1) + 'MBefore.csv')\n",
    "        adj_matB = read_txt(filename=pathIn + str(iRow+1) + 'MAfter.csv')\n",
    "        nSize   = nrow(adj_matA)\n",
    "        nSource = int(allComb[iRow][0])\n",
    "        nSink   = int(allComb[iRow][0])\n",
    "        nTrauma = int(allComb[iRow][1])\n",
    "        maxflowBefore = int(allComb[iRow][2])\n",
    "        maxflowAfter  = int(allComb[iRow][3])\n",
    "        \n",
    "        timeStart = time.time()\n",
    "        costAfter   = process_graph_LPSolver(adj_matrix=adj_matB, \n",
    "                                              cost_function=cost_function, \n",
    "                                              flow_val=maxflowBefore, \n",
    "                                              sources= list(range(0, nSource)),\n",
    "                                              sinks = list(range(nSize-nSink, nSize)))\n",
    "        timeCost  = time.time() - timeStart\n",
    "        allComb[iRow].append(costAfter)\n",
    "        allComb[iRow].append(timeCost)\n",
    "        print(str(allComb[iRow]))\n",
    "    write_txt(pathOut + 'allComb_out.csv', allComb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(list(range(0,10,1)))\n",
    "# print(nSize)\n",
    "# print(nSource)\n",
    "# print(nSink)\n",
    "# print(pAddEdge)\n",
    "# print(nTrauma)\n",
    "# print(list(range(0, nSource)))\n",
    "# print(list(range(nSize-nSink, nSize)))\n",
    "# print(costBefore)\n",
    "# print(costAfter)\n",
    "# print(allComb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "calculate cost using LP Solver\n",
    "\n",
    "Inputs:\n",
    "adj_matrix    - n*n matrix represented as a list of lists in python as shown below, 1 represents an edge from i->j\n",
    "sources       - list of vertices that are sources\n",
    "sinks         - list of vertices that are sinks\n",
    "flow_val      - Value of flow that we want to reinstate\n",
    "cost_function - cost function \n",
    "'''\n",
    "def process_graph_LPSolver(adj_matrix, sources, sinks, flow_val, cost_function):\n",
    "    #Preprocess graph, prepare variables and vertex dictionary for LP program\n",
    "    transition_matrix,edge_capacity_factors,edge_flows,vertex_dict = preprocess_graph(adj_matrix,sources,sinks)\n",
    "    source = 0 #super source\n",
    "    sink = len(transition_matrix)-1 #super sink\n",
    "    CAP_UB = flow_val * len(adj_matrix)\n",
    "    cap_dict = {}\n",
    "    for i in range(len(transition_matrix[source])):\n",
    "        if(transition_matrix[0][i] == 1):\n",
    "            cf = 'x_0'+'_'+str(i)\n",
    "            cap_dict[cf] = len(vertex_dict[i]['o'])\n",
    "\n",
    "    for i in range(len(sinks)):\n",
    "        new_sink_idx = sinks[i]+1\n",
    "        cf = 'x_'+str(new_sink_idx)+'_'+str(sink)\n",
    "        cap_dict[cf] = len(vertex_dict[new_sink_idx]['i'])\n",
    "    \n",
    "    '''\n",
    "    LP Problem formulation\n",
    "    '''\n",
    "    lp_problem = pulp.LpProblem(\"Graph min cost\", pulp.LpMinimize)\n",
    "    edge_cap_vars = LpVariable.dicts(\"EdgeCaps\",edge_capacity_factors,1)\n",
    "    edge_flow_vars = LpVariable.dicts(\"EdgeFlows\",edge_flows,0)\n",
    "\n",
    "    #Objective function\n",
    "    lp_problem += lpSum([(edge_cap_vars[i] - 1) for i in edge_capacity_factors]), \"Z\"\n",
    "\n",
    "    #Flow conservation constraints for nodes besides source and sink\n",
    "    for i in range(len(vertex_dict)):\n",
    "        if(i != source and i != sink):\n",
    "            lp_problem += lpSum([edge_flow_vars[j] for j in vertex_dict[i]['i']]) >= lpSum([edge_flow_vars[k] for k in vertex_dict[i]['o']])\n",
    "            lp_problem += lpSum([edge_flow_vars[j] for j in vertex_dict[i]['i']]) <= lpSum([edge_flow_vars[k] for k in vertex_dict[i]['o']])\n",
    "\n",
    "    #Flow conservation for source\n",
    "    lp_problem += lpSum([edge_flow_vars[j] for j in vertex_dict[source]['o']]) >= flow_val\n",
    "    lp_problem += lpSum([edge_flow_vars[j] for j in vertex_dict[source]['o']]) <= flow_val\n",
    "\n",
    "    #Flow conservation for sink\n",
    "    lp_problem += lpSum([edge_flow_vars[j] for j in vertex_dict[sink]['i']]) >= flow_val\n",
    "    lp_problem += lpSum([edge_flow_vars[j] for j in vertex_dict[sink]['i']]) <= flow_val\n",
    "\n",
    "    #Capacity constraints\n",
    "    for cap, flow in zip(edge_capacity_factors, edge_flows):\n",
    "        cap_multiplier = 1\n",
    "        if(cap in cap_dict):\n",
    "            cap_multiplier = CAP_UB\n",
    "        lp_problem += edge_flow_vars[flow] <= edge_cap_vars[cap]*cap_multiplier\n",
    "    \n",
    "    #Solve LP_problem\n",
    "    lp_problem.solve()\n",
    "    \n",
    "    assert(pulp.LpStatus[lp_problem.status] == 'Optimal')\n",
    "    \n",
    "    #compute total cost\n",
    "    capValues = [v.varValue for v in lp_problem.variables()[0:(len(edge_cap_vars))]]\n",
    "    cost = sum([cost_function(cap, 0) for cap in capValues])\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Main Input to the program\n",
    "adj_matrix - n*n matrix represented as a list of lists in python as shown below, 1 represents an edge from i->j\n",
    "sources - list of vertices that are sources\n",
    "sinks - list of vertices that are sinks\n",
    "flow_val - Value of flow that we want to reinstate\n",
    "\n",
    "Example\n",
    "\n",
    "adj_matrix = [[0,1,0,0],[0,0,1,1],[0,0,0,0],[0,0,1,0]]\n",
    "sources = [0]\n",
    "sinks = [2]\n",
    "flow_val = 2\n",
    "'''\n",
    "def main():\n",
    "    # adj_matrix = [[0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "    # [0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0], \n",
    "    # [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], \n",
    "    # [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0], \n",
    "    # [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0], \n",
    "    # [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0], \n",
    "    # [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0], \n",
    "    # [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    # [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], \n",
    "    # [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \n",
    "    # [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \n",
    "    # [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
    "    '''test for process_graph_LPSolver'''\n",
    "    #     adj_matrix = read_txt('Adj_Matrix0.txt')\n",
    "    #     sources = [0,1,2]\n",
    "    #     sinks = [9,10,11]\n",
    "    #     flow_val = 3\n",
    "    #     cost = process_graph_LPSolver(adj_matrix, sources, sinks, flow_val, cost_function)\n",
    "    #     print(cost)\n",
    "    '''test for linear cost function'''\n",
    "#     pathIn  = 'testcases/linear/';\n",
    "#     pathOut = 'testcases/linear/'\n",
    "#     test_linear(pathIn, pathOut)\n",
    "    pathIn  = 'testcases/sizeofgraphset2/';\n",
    "    pathOut = 'testcases/sizeofgraphset2/'\n",
    "    test_linear(pathIn, pathOut)\n",
    "#     '''testcase from bn_datasets'''\n",
    "#     pathIn   = 'bn_dataset/out/bn-cat-mixed-species_brain_1.txt';\n",
    "#     pathOut  = 'bn_dataset/out/bn-cat-mixed-species_brain_1.txt';\n",
    "#     test_linear_bnds(pathIn, pathOut)\n",
    "#     pathIn   = 'bn_dataset/out/bn-fly-drosophila_medulla_1.txt';\n",
    "#     pathOut  = 'bn_dataset/out/bn-fly-drosophila_medulla_1.txt';\n",
    "#     test_linear_bnds(pathIn, pathOut)\n",
    "#     pathIn   = 'bn_dataset/out/bn-macaque-rhesus_brain_1.txt';\n",
    "#     pathOut  = 'bn_dataset/out/bn-macaque-rhesus_brain_1.txt';\n",
    "#     test_linear_bnds(pathIn, pathOut)\n",
    "#     pathIn   = 'bn_dataset/out/bn-mouse_brain_1.txt';\n",
    "#     pathOut  = 'bn_dataset/out/bn-mouse_brain_1.txt';\n",
    "#     test_linear_bnds(pathIn, pathOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_matrix = [[0,1,0,0],[0,0,1,1],[0,0,0,0],[0,0,1,0]]\n",
    "sources = [0]\n",
    "sinks = [2]\n",
    "flow_val = 2\n",
    "cost = process_graph_LPSolver(adj_matrix, sources, sinks, flow_val, cost_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: 0\n",
      "['200', '16', '16', '0.2', '2', '586', '580']\n",
      "['200', '16', '16', '0.2', '2', '586', '580', 0.0, 6.0, 1.6949331760406494]\n",
      "processing: 1\n",
      "['200', '16', '16', '0.2', '10', '601', '566']\n",
      "['200', '16', '16', '0.2', '10', '601', '566', 0.0, 35.0, 1.650306224822998]\n",
      "processing: 2\n",
      "['200', '16', '16', '0.2', '40', '591', '450']\n",
      "['200', '16', '16', '0.2', '40', '591', '450', 0.0, 141.0, 1.6315782070159912]\n",
      "processing: 3\n",
      "['200', '16', '16', '0.2', '100', '581', '273']\n",
      "['200', '16', '16', '0.2', '100', '581', '273', 0.0, 308.0, 1.6398651599884033]\n",
      "processing: 4\n",
      "['200', '16', '16', '0.2', '160', '549', '76']\n",
      "['200', '16', '16', '0.2', '160', '549', '76', 0.0, 473.0, 1.4407110214233398]\n",
      "processing: 5\n",
      "['200', '16', '16', '0.8', '2', '2348', '2323']\n",
      "['200', '16', '16', '0.8', '2', '2348', '2323', 0.0, 25.0, 8.849464654922485]\n",
      "processing: 6\n",
      "['200', '16', '16', '0.8', '10', '2359', '2228']\n",
      "['200', '16', '16', '0.8', '10', '2359', '2228', 0.0, 131.0, 11.137988090515137]\n",
      "processing: 7\n",
      "['200', '16', '16', '0.8', '40', '2332', '1805']\n",
      "['200', '16', '16', '0.8', '40', '2332', '1805', 0.0, 527.0, 9.1339271068573]\n",
      "processing: 8\n",
      "['200', '16', '16', '0.8', '100', '2330', '1058']\n",
      "['200', '16', '16', '0.8', '100', '2330', '1058', 0.0, 1272.0, 8.264976024627686]\n",
      "processing: 9\n",
      "['200', '16', '16', '0.8', '160', '2331', '308']\n",
      "['200', '16', '16', '0.8', '160', '2331', '308', 0.0, 2023.0, 8.816609144210815]\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
